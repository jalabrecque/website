---
title: "Workshop: What to do when you have unmeasured confounding (which is always)"
summary: Journal club
output:
  html_document:
    keep_md: false
    toc: true
    toc_float: true
    css: style.css

---

</br>            
**Date:** 9-13h, June 21   
**Location:** FF321 [(Map of Erasmus MC)](https://generationr.nl/wp-content/uploads/2017/07/plattegrond-Erasmus.jpg)

Note: No preparation required for the workshop. The references below are for your own knowledge.

</br>
</br>
Science is all about trying to make arguments to support statements about reality. But we never usually teach it that way. We usually teach students a recipe that they need to follow in order to get published. For example, in epidemiology or public health, this usually involves some form of looking at the relationship between two variables after you've adjusted for a bunch of other variables and if the p-value is less than 0.05 we say we've found an "association". Of course, part of this ritual dance is also to say somewhere in the discussion that there is always the possibility that the results are due to unmeasured confounding.

I have something I like to call Pete Holmes Moments. Pete Holmes is a comedian who has an [explicitly-worded rant](https://www.youtube.com/watch?v=OyDpS-GftCk) about how some of the basic facts of reality, in his words, "make no sense". In other words, reality has some aspects of it that are so mind-bogglingly weird but we've just become blind to this weirdness and craziness. 

I have Pete Holmes Moments all the time in research. For example, people use null hypothesis testing all the time but how many people can actually tell you anything about how they work (other than p<0.05 is significant). That makes no sense. Another Pete Holmes Moment, and the topic of this workshop, is that we always just casually say that one of the most important assumptions of a causal analysis, no unmeasured confounding, might be violated. If we weren't so used to reading that sentence, our reaction should be:

> "Wait, what? Uh, how much am I supposed to believe your results if there's a possibility of unmeasured confounding? Can you give me some sort of estimate for how likely unmeasured is to explain your results? How much bias could there plausibly be?"

Without answer to these questions, how do we know how much to believe a result? The answer is that we don't know. In this workshop we'll be talking about partial identification, triangulation and bias analysis, which are all methods you can use if you want to go deeper than just saying, "maybe there's unmeasured confounding." None of these methods is a slam-dunk method that will say for certain whether there is or isn't unmeasured confounding and they can require some thinking to use, but they can give a reader a much better feeling for how much unmeasured confounding might affect a result.
</br>
</br>
</br>

## Outline

[All the slides and the exercise can be found by clicking here.](https://drive.google.com/drive/folders/1M-XmL51IqNJkVpy0ChVSHR8-wUDbApX3?usp=sharing) 

- [Introduction](#intro)
- [Partial identification](#partial)
- [Triangulation](#triangulation)
- [Bias analysis](#bias_analysis)
- [Feedback](#feedback)


</br>
</br>
</br>







## Introduction{#intro}

Before I begin talking about fancier things, I need to make sure we're all on the same page with regards to causal inference and causal assumptions. This part of the workshop will also motivate the rest of the workshop. 

<!-- **Slides** -->


<!-- - Exercise -->




**The consistency assumption:**

- Section 3.4 in [What If? (Hernan and Robins 2023)](https://www.hsph.harvard.edu/miguel-hernan/wp-content/uploads/sites/1268/2023/05/hernanrobins_WhatIf_14may23.pdf)
- [Concerning the consistency assumption in causal inference, (Vanderweele, 2009)](https://pubmed.ncbi.nlm.nih.gov/19829187/)
- [Race and Sex are Causes (Glymour and Glymour 2014)](https://journals.lww.com/epidem/Fulltext/2014/07000/Commentary__Race_and_Sex_Are_Causes.3.aspx)
- [Causal identification: a charge of epidemiology in danger of marginalization (Schwartz et al 2016)](https://pubmed.ncbi.nlm.nih.gov/27237595/)
- [There is no virtue in Vagueness (Kaufman 2016)](https://pubmed.ncbi.nlm.nih.gov/27641315/)
   


</br>
</br>
</br>

## Partial Identification{#partial}

</br>

**The basic idea:** We can make weaker but more believable assumptions than "no uncontrolled confounding" to end up with a bound rather than a point estimate. In other words, we get limits on what the true effect could be (given the assumptions we make are true, of course) instead of one point estimate.

**Readings:**

- [Communicating uncertainty in policy analysis.](https://www.pnas.org/doi/pdf/10.1073/pnas.1722389115) Manski, 2019.
- [Patient Care Under Uncertainty (Manski 2019)](https://press.princeton.edu/books/hardcover/9780691194738/patient-care-under-uncertainty)
- [Nonparametric Bounds on Treatment Effects (Manski 1990)](https://www.jstor.org/stable/2006592)
- [Bounding the per-protocol effect in randomized trials: an application to colorectal cancer screening (Swanson et al 2015)](https://pubmed.ncbi.nlm.nih.gov/26620120/)
- [The analysis of randomized and non-randomized AIDS treatment trials using a new approach to causal inference in longitudinal studies (Robins 1989)](https://www.hsph.harvard.edu/wp-content/uploads/sites/343/2013/03/nchsr.pdf)
</br>
</br>
</br>



## Bias analysis{#bias_analysis}

</br>

**The basic idea:** Sometimes we know something about a confounder that we were not able to measured. Bias analysis can help estimate what answer you would have been if you had adjusted for that confounder. Bias analysis can also be used to find out how strong an unmeasured confounder would have to be to completely explain away your results. 

**Readings:**

- [Applying Quantitative Bias Analysis to Epidemiologic Data (Fox et al)](https://link.springer.com/book/10.1007/978-3-030-82673-4)
- [Sensitivity Analyses for Unmeasured Confounders](https://link.springer.com/article/10.1007/s40471-022-00308-6)
- [Bias analysis gone bad (Lash et al 2021)](https://academic.oup.com/aje/article/190/8/1604/6189735)
- [Sensitivity analysis in observational research (Vanderweele and Ding 2017)](https://pubmed.ncbi.nlm.nih.gov/28693043/)
- [The importance of making assumptions in bias analysis (MacLehose et al 2021)](https://pubmed.ncbi.nlm.nih.gov/34224472/)

</br>
</br>
</br>

## Triangulation {#triangulation}

</br>

**The basic idea:** Sometimes we can get two answers to the same question that rely on different causal assumptions. If two estimates the rely on different assumptions agree, _sometimes_ we can be more confident that the estimates are unbiased.

**Readings:**  

- [Triangulation in aetiological epidemiology (lawlor et al 2016)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5841843/)
- [Alternative causal inference methods in population health research: Evaluating tradeoffs and triangulating evidence (Matthay et al 2020)](https://www.sciencedirect.com/science/article/pii/S2352827319301545)
- [Triangulating Evidence through the Inclusion of Genetically Informed Designs (Munafò et al 2021)](https://pubmed.ncbi.nlm.nih.gov/33355252/)


## Feedback {#feedback}

<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSd_mt8nOwOKDRrGpkZfR_bvowLinGCq2-J_KI1QG_GQANJLoQ/viewform?embedded=true" width="640" height="558" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>

